{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T02:16:35.046705Z",
     "iopub.status.busy": "2023-09-09T02:16:35.045665Z",
     "iopub.status.idle": "2023-09-09T02:16:35.051482Z",
     "shell.execute_reply": "2023-09-09T02:16:35.050504Z",
     "shell.execute_reply.started": "2023-09-09T02:16:35.046570Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install wandb\n",
    "# ! pip install pydot\n",
    "# ! pip install graphviz\n",
    "# ! pip install datasets\n",
    "# ! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T02:16:35.077597Z",
     "iopub.status.busy": "2023-09-09T02:16:35.076805Z",
     "iopub.status.idle": "2023-09-09T02:16:43.964860Z",
     "shell.execute_reply": "2023-09-09T02:16:43.963905Z",
     "shell.execute_reply.started": "2023-09-09T02:16:35.077562Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datasets import load_from_disk\n",
    "from IPython.display import Image\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import (BatchNormalization, Conv2D, Dense, Dropout, GlobalAveragePooling2D, Input,\n",
    "                                     InputLayer, MaxPool2D)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_SUFFIX = \"frequency_classifier_multi\"\n",
    "ENTITY = \"makersplace\"\n",
    "PROJECT = f\"ai-or-not-{PROJECT_SUFFIX}\"\n",
    "SEED = 7\n",
    "RUNTIME_DATE_SUFFIX = \"%m%d_%H%M\"\n",
    "\n",
    "# current time\n",
    "JOB_TYPE_SUFFIX = f\"{PROJECT_SUFFIX}_M\"\n",
    "RUN_NAME_SUFFIX = datetime.now().strftime(RUNTIME_DATE_SUFFIX)\n",
    "\n",
    "\n",
    "# Datasets Paths\n",
    "training_dataset_path = \"../cache/data/training_dataset\"\n",
    "validation_dataset_path = \"../cache/data/validation_dataset\"\n",
    "\n",
    "# Model Paths\n",
    "cnn_model_path = Path(f\"../cache/models/{JOB_TYPE_SUFFIX}/cnn_{RUN_NAME_SUFFIX}\")\n",
    "effv2_model_dir_path = Path(f\"../cache/models/{JOB_TYPE_SUFFIX}/en2s_{RUN_NAME_SUFFIX}\")\n",
    "\n",
    "\n",
    "# Deleted and recreated training and validation dataset folders\n",
    "CLEAN_RUN = False\n",
    "\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# WANDB Login\n",
    "os.environ[\"WANDB_API_KEY\"] = \"d13afab09b400fc9d606e612d806a4b0740790fd\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATION = {\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"IM_SIZE\": 128,\n",
    "    \"DROPOUT_RATE\": 0.1,\n",
    "    \"N_EPOCHS\": 15,\n",
    "    \"REGULARIZATION_RATE\": 0.01,\n",
    "    \"N_FILTERS\": 6,\n",
    "    \"KERNEL_SIZE\": 3,\n",
    "    \"N_STRIDES\": 1,\n",
    "    \"POOL_SIZE\": 2,\n",
    "    \"N_DENSE_1\": 2048,\n",
    "    \"N_DENSE_2\": 1024,\n",
    "    \"N_DENSE_3\": 256,\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"CHANNELS\": 3,\n",
    "    \"CLASS_NAMES\": [\"REAL\", \"ADM\", \"SDv1\", \"MD\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIRECTORIES = [\n",
    "    # Label 0\n",
    "    (\"DIRE/train/imagenet/real\", 0, \"*/*\"),\n",
    "    (\"DIRE/train/celebahq/real\", 0, \"*\"),\n",
    "    (\"DIRE/train/lsun_bedroom/real\", 0, \"*\"),\n",
    "    (\"cifake/train/REAL\", 0, \"*\"),\n",
    "    # Label 1\n",
    "    (\"DIRE/train/imagenet/adm\", 1, \"*/*\"),\n",
    "    (\"DIRE/train/lsun_bedroom/adm\", 1, \"*\"),\n",
    "    # Label 2\n",
    "    (\"cifake/train/FAKE\", 2, \"*\"),  # Generated by SD 1.4\n",
    "    (\n",
    "        \"FakeImageDataset/ImageData/train/SDv15R-CC1M/SDv15R-dpmsolver-25-1M/SDv15R-CC1M\",\n",
    "        2,\n",
    "        \"*\",\n",
    "    ),  # Generated by SD 1.5\n",
    "    (\"DIRE/train/celebahq/sdv2\", 2, \"*/*\"),\n",
    "    # Label 3\n",
    "    (\"FakeImageDataset/ImageData/val/Midjourneyv5-5K/Midjourneyv5-5K_train\", 3, \"*\"),\n",
    "]\n",
    "# Randomize the order of the training directories\n",
    "# np.random.shuffle(train_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Directories\n",
    "TEST_SHARDS = 1\n",
    "test_directories = [\n",
    "    # Label 0\n",
    "    (\"../cache/data/cifake/test/REAL\", 0, \"*\", TEST_SHARDS, 0),\n",
    "    (\"../cache/data/DIRE/test/imagenet/real\", 0, \"*/*\", TEST_SHARDS, 0),\n",
    "    (\"../cache/data/DIRE/test/celebahq/real\", 0, \"*\", TEST_SHARDS, 0),\n",
    "    # Label 1\n",
    "    (\"../cache/data/DIRE/test/imagenet/adm\", 1, \"*/*\", TEST_SHARDS, 0),\n",
    "    # Label 2\n",
    "    (\"../cache/data/cifake/test/FAKE\", 2, \"*\", TEST_SHARDS, 0),  # Generated by SD 1.4\n",
    "    (\"../cache/data/DIRE/test/imagenet/sdv1\", 2, \"*/*\", TEST_SHARDS, 0),  # Bad 73\n",
    "    (\"../cache/data/DIRE/test/lsun_bedroom/sdv1_new\", 2, \"*\", TEST_SHARDS, 0),\n",
    "    (\n",
    "        \"../cache/data/FakeImageDataset/ImageData/val/SDv15-CC30K/SDv15-CC30K\",\n",
    "        2,\n",
    "        \"*/*\",\n",
    "        6,\n",
    "        0,\n",
    "    ),\n",
    "    # Label 3\n",
    "    (\"../cache/data/DIRE/test/lsun_bedroom/sdv2\", 2, \"*\", TEST_SHARDS, 0),\n",
    "    (\"../cache/data/DIRE/test/celebahq/sdv2\", 2, \"*\", TEST_SHARDS, 0),\n",
    "    (\n",
    "        \"../cache/data/FakeImageDataset/ImageData/val/SDv21-CC15K/SDv21-CC15K/SDv2-dpmsolver-25-10K\",\n",
    "        2,\n",
    "        \"*\",\n",
    "        2,\n",
    "        0,\n",
    "    ),  # Bad 79\n",
    "    # Label 4\n",
    "    (\n",
    "        \"../cache/data/FakeImageDataset/ImageData/val/Midjourneyv5-5K/Midjourneyv5-5K_test\",\n",
    "        3,\n",
    "        \"*\",\n",
    "        TEST_SHARDS,\n",
    "        0,\n",
    "    ),  # Bad  65\n",
    "    (\n",
    "        \"../cache/data/DIRE/test/lsun_bedroom/midjourney\",\n",
    "        3,\n",
    "        \"*\",\n",
    "        TEST_SHARDS,\n",
    "        0,\n",
    "    ),  # Bad < 13\n",
    "    # # AI Artbench Dataset\n",
    "    # (\"../cache/data/ai-artbench/test/AI*\", 1.0, \"*\", TEST_SHARDS, 0),  # 675 Batches\n",
    "    # (\"../cache/data/ai-artbench/test/real\", 0.0, \"*/*\", TEST_SHARDS, 0),\n",
    "    # # CIFAKE Dataset\n",
    "    # (\"../cache/data/FakeImageDataset/ImageData/val/cogview2-22K/cogview2-22K\", 1.0, \"*\", TEST_SHARDS, 0),\n",
    "    # DIRE Imagenet Dataset\n",
    "    # (\"../cache/data/DIRE/test/celebahq/if\", 1.0, \"*\", TEST_SHARDS, 0),\n",
    "    # (\"../cache/data/DIRE/test/celebahq/dalle2\", 1.0, \"*\", TEST_SHARDS, 0),\n",
    "    # # DIRE Lsun Bedroom Dataset\n",
    "    # (\"../cache/data/DIRE/test/lsun_bedroom/dalle2\", 1.0, \"*\", TEST_SHARDS, 0),\n",
    "    # (\"../cache/data/DIRE/test/lsun_bedroom/vqdiffusion\", 1.0, \"*\", TEST_SHARDS, 0),\n",
    "    # FakeImageDataset\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading and Tranformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image):\n",
    "    image = tf.image.resize_with_pad(\n",
    "        image=image,\n",
    "        target_height=CONFIGURATION[\"IM_SIZE\"],\n",
    "        target_width=CONFIGURATION[\"IM_SIZE\"],\n",
    "    )\n",
    "    # divide by 255 to normalize\n",
    "    image = image / 255.0\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "    img = tf.io.decode_image(img, channels=3)\n",
    "    return resize_image(img)\n",
    "\n",
    "\n",
    "def process_path(file_path):\n",
    "    # Load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "# write a function apply Fourier Transform to the image and return the image\n",
    "def apply_fourier_transform(image):\n",
    "    # print(f\"Image shape: {image.shape}\")\n",
    "    # extract r channel from the image\n",
    "    r = image[:, :, 0]\n",
    "    # extract g channel from the image\n",
    "    g = image[:, :, 1]\n",
    "    # extract b channel from the image\n",
    "    b = image[:, :, 2]\n",
    "\n",
    "    # apply fourier transform to the image\n",
    "    r = tf.signal.fft2d(tf.cast(r, dtype=tf.complex64))\n",
    "    g = tf.signal.fft2d(tf.cast(g, dtype=tf.complex64))\n",
    "    b = tf.signal.fft2d(tf.cast(b, dtype=tf.complex64))\n",
    "    # # shift the zero-frequency component to the center of the spectrum\n",
    "    r = tf.signal.fftshift(r)\n",
    "    g = tf.signal.fftshift(g)\n",
    "    b = tf.signal.fftshift(b)\n",
    "    # apply log to the image enhance the magnitude of the image and to reduce the dynamic range of the data for visualization\n",
    "    r = 20 * tf.math.log(tf.abs(r) + 1)\n",
    "    g = 20 * tf.math.log(tf.abs(g) + 1)\n",
    "    b = 20 * tf.math.log(tf.abs(b) + 1)\n",
    "    # normalize the value using min-max normalization\n",
    "    r = (r - tf.reduce_min(r)) / (tf.reduce_max(r) - tf.reduce_min(r))\n",
    "    g = (g - tf.reduce_min(g)) / (tf.reduce_max(g) - tf.reduce_min(g))\n",
    "    b = (b - tf.reduce_min(b)) / (tf.reduce_max(b) - tf.reduce_min(b))\n",
    "    # merge channels\n",
    "    if CONFIGURATION[\"CHANNELS\"] == 6:\n",
    "        o_r = image[:, :, 0]\n",
    "        o_g = image[:, :, 1]\n",
    "        o_b = image[:, :, 2]\n",
    "        image = tf.stack([o_r, o_g, o_b, r, g, b], axis=-1)\n",
    "    else:\n",
    "        image = tf.stack([r, g, b], axis=-1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize_dataset(samples):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    index = 1\n",
    "    for image, label in samples:\n",
    "        plt.subplot(4, 4, index)\n",
    "        plt.imshow(image)\n",
    "        title = CONFIGURATION[\"CLASS_NAMES\"][int(label)]\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        index += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_custom_dataset(directory, label, pattern):\n",
    "    # if directory path contains 'aiornot' load it as tf dataset else load it as a custom dataset\n",
    "    if \"aiornot\" in directory:\n",
    "        read_aiornot = load_from_disk(dataset_path=directory)\n",
    "        dataset = read_aiornot.to_tf_dataset(\n",
    "            columns=\"image\",\n",
    "            label_cols=\"label\",\n",
    "        )\n",
    "        dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32), y))\n",
    "        dataset = dataset.map(lambda x, y: (resize_image(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    else:\n",
    "        list_ds = tf.data.Dataset.list_files(str(Path(directory) / pattern), shuffle=True)\n",
    "        dataset = list_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.map(lambda x: (x, label))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Dataset Creation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare empty dataset for trainingn and validation\n",
    "training_dataset = None\n",
    "validation_dataset = None\n",
    "\n",
    "for directory, label, pattern, shards, shard_index in train_directories:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "**********************************************************************************************************************************          \n",
    "          Directory:  {directory} \n",
    "**********************************************************************************************************************************\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    current_dataset = get_custom_dataset(directory, label, pattern)\n",
    "\n",
    "    if shards > 1:\n",
    "        # shard the dataset\n",
    "        current_dataset = current_dataset.shard(num_shards=shards, index=shard_index)\n",
    "\n",
    "    # split dataset into train and validation\n",
    "    dataset_size = len(current_dataset)\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    validation_size = int(0.2 * dataset_size)\n",
    "\n",
    "    current_train_dataset = current_dataset.skip(validation_size)\n",
    "    current_validation_dataset = current_dataset.take(validation_size)\n",
    "\n",
    "    if training_dataset is None:\n",
    "        training_dataset = current_train_dataset\n",
    "    else:\n",
    "        training_dataset = training_dataset.concatenate(current_train_dataset)\n",
    "\n",
    "    if validation_dataset is None:\n",
    "        validation_dataset = current_validation_dataset\n",
    "    else:\n",
    "        validation_dataset = validation_dataset.concatenate(current_validation_dataset)\n",
    "\n",
    "    # VISUALIZE DATASET\n",
    "    visualize_dataset(current_dataset.take(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply fourier transform to the image\n",
    "training_dataset = training_dataset.map(lambda x, y: (apply_fourier_transform(x), y))\n",
    "validation_dataset = validation_dataset.map(lambda x, y: (apply_fourier_transform(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T02:19:09.162535Z",
     "iopub.status.busy": "2023-09-09T02:19:09.161842Z",
     "iopub.status.idle": "2023-09-09T02:19:11.442569Z",
     "shell.execute_reply": "2023-09-09T02:19:11.441450Z",
     "shell.execute_reply.started": "2023-09-09T02:19:09.162503Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataset = (\n",
    "    training_dataset.shuffle(buffer_size=20_000, seed=SEED)\n",
    "    .batch(CONFIGURATION[\"BATCH_SIZE\"])\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_dataset = validation_dataset.batch(CONFIGURATION[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "# visualize_dataset(training_dataset.take(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_RUN:\n",
    "    if os.path.exists(training_dataset_path):\n",
    "        # remove directory recursively\n",
    "        shutil.rmtree(training_dataset_path)\n",
    "\n",
    "    if os.path.exists(validation_dataset_path):\n",
    "        shutil.rmtree(validation_dataset_path)\n",
    "\n",
    "if not os.path.exists(training_dataset_path):\n",
    "    training_dataset.save(training_dataset_path)\n",
    "\n",
    "if not os.path.exists(validation_dataset_path):\n",
    "    validation_dataset.save(validation_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset sets from disk\n",
    "training_dataset = tf.data.Dataset.load(training_dataset_path)\n",
    "validation_dataset = tf.data.Dataset.load(validation_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for image, label in training_dataset.take(1):\n",
    "    for index in range(16):\n",
    "        ax = plt.subplot(4, 4, index + 1)\n",
    "        # extract red channel from the image\n",
    "        plt.imshow(image[index][:, :, 0])\n",
    "        # plt.imshow(image[index])\n",
    "        plt.title(CONFIGURATION[\"CLASS_NAMES\"][int(label[index])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T02:19:11.476780Z",
     "iopub.status.busy": "2023-09-09T02:19:11.476126Z",
     "iopub.status.idle": "2023-09-09T02:19:11.483954Z",
     "shell.execute_reply": "2023-09-09T02:19:11.482820Z",
     "shell.execute_reply.started": "2023-09-09T02:19:11.476733Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reduce LR On no Improvement\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    min_delta=0.001,\n",
    "    cooldown=0,\n",
    "    min_lr=1e-15,\n",
    ")\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    patience=8,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effv2_model_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "effv2_model_best_weights_path = effv2_model_dir_path / \"best_weights\"\n",
    "effv2_model_saved_model_path = effv2_model_dir_path / \"saved_model\"\n",
    "\n",
    "\n",
    "wandb_run = wandb.init(\n",
    "    entity=ENTITY,\n",
    "    project=PROJECT,\n",
    "    job_type=f\"effv2s_{JOB_TYPE_SUFFIX}\",\n",
    "    name=f\"fc_layers_{RUN_NAME_SUFFIX}\",\n",
    "    reinit=True,\n",
    "    config=CONFIGURATION,\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Checkpointing\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    effv2_model_best_weights_path,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    ")\n",
    "\n",
    "backbone = tf.keras.applications.EfficientNetV2S(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=(\n",
    "        CONFIGURATION[\"IM_SIZE\"],\n",
    "        CONFIGURATION[\"IM_SIZE\"],\n",
    "        CONFIGURATION[\"CHANNELS\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "backbone.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnetv2s_model = tf.keras.Sequential(\n",
    "    [\n",
    "        Input(\n",
    "            shape=(\n",
    "                CONFIGURATION[\"IM_SIZE\"],\n",
    "                CONFIGURATION[\"IM_SIZE\"],\n",
    "                CONFIGURATION[\"CHANNELS\"],\n",
    "            )\n",
    "        ),\n",
    "        backbone,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(\n",
    "            CONFIGURATION[\"N_DENSE_1\"],\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=L2(CONFIGURATION[\"REGULARIZATION_RATE\"]),\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        Dropout(rate=CONFIGURATION[\"DROPOUT_RATE\"]),\n",
    "        Dense(\n",
    "            CONFIGURATION[\"N_DENSE_2\"],\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=L2(CONFIGURATION[\"REGULARIZATION_RATE\"]),\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        Dropout(rate=CONFIGURATION[\"DROPOUT_RATE\"]),\n",
    "        Dense(\n",
    "            CONFIGURATION[\"N_DENSE_3\"],\n",
    "            activation=\"relu\",\n",
    "            kernel_regularizer=L2(CONFIGURATION[\"REGULARIZATION_RATE\"]),\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        Dense(len(CONFIGURATION[\"CLASS_NAMES\"]), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "efficientnetv2s_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    efficientnetv2s_model,\n",
    "    to_file=\"efficientnet_b4_model.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")\n",
    "Image(filename=\"efficientnet_b4_model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "efficientnetv2s_model.compile(\n",
    "    optimizer=Adam(learning_rate=CONFIGURATION[\"LEARNING_RATE\"]),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "efficientnetv2s_history = efficientnetv2s_model.fit(\n",
    "    training_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=CONFIGURATION[\"N_EPOCHS\"] * 3,\n",
    "    callbacks=[\n",
    "        reduce_lr,\n",
    "        model_checkpoint,\n",
    "        early_stopping,\n",
    "        WandbCallback(save_model=False),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_classification_report(model, dataset, wandb_run):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for image, label in dataset:\n",
    "        y_true.extend(label.numpy())\n",
    "\n",
    "    y_pred = model.predict(dataset)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    report = classification_report(\n",
    "        y_true,\n",
    "        y_pred_labels,\n",
    "        target_names=CONFIGURATION[\"CLASS_NAMES\"],\n",
    "        output_dict=True,\n",
    "    )\n",
    "\n",
    "    avg_report_df = pd.DataFrame()\n",
    "    avg_report_df[\"model\"] = [wandb_run.name]\n",
    "    avg_report_df[\"Avg precision\"] = [report[\"macro avg\"][\"precision\"]]\n",
    "    avg_report_df[\"Avg recall\"] = [report[\"macro avg\"][\"recall\"]]\n",
    "    avg_report_df[\"Avg F1\"] = [report[\"macro avg\"][\"f1-score\"]]\n",
    "    avg_report_df[\"Avg accuracy\"] = [report[\"accuracy\"]]\n",
    "    avg_report_df[\"Avg support\"] = [report[\"macro avg\"][\"support\"]]\n",
    "\n",
    "    label_reoprt_df = pd.DataFrame()\n",
    "    label_reoprt_df[\"model\"] = [wandb_run.name]\n",
    "    for class_name in CONFIGURATION[\"CLASS_NAMES\"]:\n",
    "        label_reoprt_df[f\"{class_name} P/R/F1\"] = (\n",
    "            f\"{report[class_name]['precision']:.2f} / {report[class_name]['recall']:.2f} / {report[class_name]['f1-score']:.2f}\"\n",
    "        )\n",
    "\n",
    "    wandb_run.log({\"Classification Report\": wandb.Table(dataframe=avg_report_df)})\n",
    "    wandb_run.log({\"Label Report\": wandb.Table(dataframe=label_reoprt_df)})\n",
    "    wandb_run.log(\n",
    "        {\n",
    "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                probs=None,\n",
    "                y_true=y_true,\n",
    "                preds=y_pred_labels,\n",
    "                class_names=CONFIGURATION[\"CLASS_NAMES\"],\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def log_test_metrics(current_model, wandb_run):\n",
    "    # declare empty dataframe and add results to it for each test dataset\n",
    "    loss_dataframe = pd.DataFrame()\n",
    "    accuracy_dataframe = pd.DataFrame()\n",
    "\n",
    "    # composite dataframe\n",
    "    composite_dataframe = pd.DataFrame()\n",
    "\n",
    "    loss_dataframe[\"model\"] = [wandb_run.name]\n",
    "    accuracy_dataframe[\"model\"] = [wandb_run.name]\n",
    "    # instantiate empty dataset\n",
    "    composite_dataset = None\n",
    "\n",
    "    # itreate through each test dataset using index\n",
    "    for index, (directory, label, pattern, shards, shard_index) in enumerate(test_directories):\n",
    "        current_dataset = get_custom_dataset(directory, label, pattern)\n",
    "        current_dataset = current_dataset.map(lambda x, y: (apply_fourier_transform(x), y))\n",
    "        # current_dataset.ignore_errors()\n",
    "        current_dataset = current_dataset.batch(CONFIGURATION[\"BATCH_SIZE\"])\n",
    "\n",
    "        # evaluate model on current_dataset and capture metrics\n",
    "        # accept only the loss and accuracy and ignore the rest irrespective of count of metrics\n",
    "        test_loss, test_accuracy = current_model.evaluate(current_dataset)\n",
    "\n",
    "        # Extract the 3rd part of the directory path\n",
    "        dataset_name = directory.split(\"/\")[3] + \" : \" + directory.split(\"/\")[-1] + \" : \" + str(index)\n",
    "\n",
    "        # add a column to the dataframe\n",
    "        loss_dataframe[dataset_name] = [test_loss]\n",
    "        accuracy_dataframe[dataset_name] = [test_accuracy]\n",
    "\n",
    "        # concatenate current dataset to composite dataset\n",
    "        if composite_dataset is None:\n",
    "            composite_dataset = current_dataset\n",
    "        else:\n",
    "            composite_dataset = composite_dataset.concatenate(current_dataset)\n",
    "\n",
    "    composite_loss, composite_accuracy = current_model.evaluate(composite_dataset)\n",
    "    composite_dataframe[\"model\"] = [wandb_run.name]\n",
    "    composite_dataframe[\"loss\"] = [composite_loss]\n",
    "    composite_dataframe[\"accuracy\"] = [composite_accuracy]\n",
    "\n",
    "    wandb_run.log({\"Loss\": wandb.Table(dataframe=loss_dataframe)})\n",
    "    wandb_run.log({\"Accuracy\": wandb.Table(dataframe=accuracy_dataframe)})\n",
    "    wandb_run.log({\"Overall Results\": wandb.Table(dataframe=composite_dataframe)})\n",
    "\n",
    "    log_classification_report(current_model, composite_dataset, wandb_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnetv2s_model.load_weights(effv2_model_best_weights_path)\n",
    "efficientnetv2s_model.save(effv2_model_saved_model_path)\n",
    "efficientnetv2s_model.evaluate(validation_dataset)\n",
    "\n",
    "log_test_metrics(efficientnetv2s_model, wandb_run)\n",
    "\n",
    "wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_run.finish()\n",
    "plt.plot(efficientnetv2s_history.history[\"loss\"])\n",
    "plt.plot(efficientnetv2s_history.history[\"val_loss\"])\n",
    "plt.title(\"EfficientNetV2 S Model Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend([\"train_loss\", \"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(efficientnetv2s_history.history[\"sparse_categorical_accuracy\"])\n",
    "plt.plot(efficientnetv2s_history.history[\"val_sparse_categorical_accuracy\"])\n",
    "plt.title(\"EfficientNetV2 S Model Accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend([\"train_accuracy\", \"val_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write a function to print confusion matrix\n",
    "# def confusion_matrix(y_true, y_pred, labels):\n",
    "#     cm = tf.math.confusion_matrix(y_true, y_pred, num_classes=len(labels))\n",
    "#     cm = cm.numpy()\n",
    "#     cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "#     return cm\n",
    "\n",
    "# composite_dataset = None\n",
    "#  # itreate through each test dataset using index\n",
    "# for index, (directory, label, pattern, shards, shard_index) in enumerate(test_directories):\n",
    "\n",
    "#     current_dataset = get_custom_dataset(directory, label, pattern)\n",
    "#     current_dataset = current_dataset.map(lambda x, y: (apply_fourier_transform(x), y))\n",
    "#     # current_dataset.ignore_errors()\n",
    "#     current_dataset = current_dataset.batch(CONFIGURATION[\"BATCH_SIZE\"])\n",
    "\n",
    "#     # concatenate current dataset to composite dataset\n",
    "#     if composite_dataset is None:\n",
    "#         composite_dataset = current_dataset\n",
    "#     else:\n",
    "#         composite_dataset = composite_dataset.concatenate(current_dataset)\n",
    "\n",
    "# y_pred = efficientnetv2s_model.predict(composite_dataset)\n",
    "# y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# y_true = []\n",
    "# for image, label in composite_dataset:\n",
    "#     y_true.extend(label.numpy())\n",
    "\n",
    "# print(confusion_matrix(y_true, y_pred_labels, CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(y_pred_labels[:100])\n",
    "# # print(y_true[:100])\n",
    "# # print confusion matrix using sklearn\n",
    "# cm = confusion_matrix(y_true, y_pred_labels, labels=CLASS_NAMES)\n",
    "\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASS_NAMES)\n",
    "# disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
