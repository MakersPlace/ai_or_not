{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T02:16:35.046705Z",
     "iopub.status.busy": "2023-09-09T02:16:35.045665Z",
     "iopub.status.idle": "2023-09-09T02:16:35.051482Z",
     "shell.execute_reply": "2023-09-09T02:16:35.050504Z",
     "shell.execute_reply.started": "2023-09-09T02:16:35.046570Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install wandb\n",
    "# ! pip install pydot\n",
    "# ! pip install graphviz\n",
    "# ! pip install datasets\n",
    "# ! pip install scikit-learn\n",
    "# ! pip install webdataset\n",
    "# ! pip install sagemaker_tensorflow # uses Linux FIFOs so does not work on Mac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T02:16:35.077597Z",
     "iopub.status.busy": "2023-09-09T02:16:35.076805Z",
     "iopub.status.idle": "2023-09-09T02:16:43.964860Z",
     "shell.execute_reply": "2023-09-09T02:16:43.963905Z",
     "shell.execute_reply.started": "2023-09-09T02:16:35.077562Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging as log\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import webdataset as wds\n",
    "from IPython.display import Image\n",
    "from webdataset import multi\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_SUFFIX = \"frequency_classifier_multi\"\n",
    "ENTITY = \"makersplace\"\n",
    "PROJECT = f\"ai-or-not-{PROJECT_SUFFIX}\"\n",
    "SEED = 7\n",
    "RUNTIME_DATE_SUFFIX = \"%m%d_%H%M\"\n",
    "\n",
    "# current time\n",
    "JOB_TYPE_SUFFIX = f\"{PROJECT_SUFFIX}_M\"\n",
    "RUN_NAME_SUFFIX = datetime.now().strftime(RUNTIME_DATE_SUFFIX)\n",
    "\n",
    "\n",
    "# Datasets Paths\n",
    "S3_BUCKET = \"mp-ml-data-dev\"\n",
    "PREFIX = \"finder/ai_or_not/ai_or_not_datasets/test_datasets/\"\n",
    "S3_PREFIX = f\"s3://{S3_BUCKET}/{PREFIX}\"\n",
    "training_dataset_path = \"../cache/data/training_dataset_tf_record_snapshot\"\n",
    "validation_dataset_path = \"../cache/data/validation_dataset_tf_record_snapshot\"\n",
    "dataset_cache_path = \"../cache/data/dataset.cache\"\n",
    "\n",
    "# Model Paths\n",
    "cnn_model_path = Path(f\"../cache/models/{JOB_TYPE_SUFFIX}/cnn_{RUN_NAME_SUFFIX}\")\n",
    "effv2_model_dir_path = Path(f\"../cache/models/{JOB_TYPE_SUFFIX}/en2s_{RUN_NAME_SUFFIX}\")\n",
    "\n",
    "\n",
    "# Deleted and recreated training and validation dataset folders\n",
    "CLEAN_RUN = True\n",
    "\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# WANDB Login\n",
    "os.environ[\"WANDB_API_KEY\"] = \"d13afab09b400fc9d606e612d806a4b0740790fd\"\n",
    "wandb.login()\n",
    "\n",
    "# log to stdout\n",
    "log.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "    level=log.INFO,\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "# create boto3 session\n",
    "boto3_session = boto3.Session(profile_name=\"dev\")\n",
    "s3_client = boto3_session.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATION = {\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"IM_SIZE\": 128,\n",
    "    \"DROPOUT_RATE\": 0.1,\n",
    "    \"N_EPOCHS\": 15,\n",
    "    \"REGULARIZATION_RATE\": 0.01,\n",
    "    \"N_FILTERS\": 6,\n",
    "    \"KERNEL_SIZE\": 3,\n",
    "    \"N_STRIDES\": 1,\n",
    "    \"POOL_SIZE\": 2,\n",
    "    \"N_DENSE_1\": 2048,\n",
    "    \"N_DENSE_2\": 1024,\n",
    "    \"N_DENSE_3\": 256,\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"CHANNELS\": 3,\n",
    "    \"CLASS_NAMES\": [\"REAL\", \"ADM\", \"SD\", \"MD\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIRECTORIES = [\n",
    "    # Label 0 - Real\n",
    "    (\"../cache/data/DIRE/train/imagenet/real\", 0, \"*/*\"),\n",
    "    (\"../cache/data/DIRE/train/celebahq/real\", 0, \"*\"),\n",
    "    (\"../cache/data/DIRE/train/lsun_bedroom/real\", 0, \"*\"),\n",
    "    (\"../cache/data/cifake/train/REAL\", 0, \"*\"),\n",
    "    # Label 1 - GAN\n",
    "    (\"../cache/data/DIRE/train/lsun_bedroom/stylegan\", 1, 0),\n",
    "    # Label 2 - Diffusion\n",
    "    (\"../cache/data/DIRE/train/imagenet/adm\", 2, \"*/*\"),\n",
    "    (\"../cache/data/DIRE/train/lsun_bedroom/adm\", 2, \"*\"),\n",
    "    # Label 3 SD\n",
    "    (\"../cache/data/cifake/train/FAKE\", 3, \"*\"),  # Generated by SD 1.4\n",
    "    (\n",
    "        \"../cache/data/FakeImageDataset/ImageData/train/SDv15R-CC1M/SDv15R-dpmsolver-25-1M/SDv15R-CC1M\",\n",
    "        3,\n",
    "        \"*\",\n",
    "    ),  # Generated by SD 1.5\n",
    "    (\"../cache/data/DIRE/train/celebahq/sdv2\", 3, \"*/*\"),\n",
    "    # Label 4 MD\n",
    "    (\"../cache/data/FakeImageDataset/ImageData/val/Midjourneyv5-5K/Midjourneyv5-5K_train\", 4, \"*\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Directories\n",
    "TEST_SHARDS = 1\n",
    "TEST_DIRECTORIES = [\n",
    "    # Label 0\n",
    "    (\"../cache/data/cifake/test/REAL\", 0, \"*\"),\n",
    "    (\"../cache/data/DIRE/test/imagenet/real\", 0, \"*/*\"),\n",
    "    (\"../cache/data/DIRE/test/celebahq/real\", 0, \"*\"),\n",
    "    # Label 1\n",
    "    (\"../cache/data/DIRE/test/imagenet/adm\", 1, \"*/*\"),\n",
    "    # Label 2\n",
    "    (\"../cache/data/cifake/test/FAKE\", 2, \"*\"),  # Generated by SD 1.4\n",
    "    (\"../cache/data/DIRE/test/imagenet/sdv1\", 2, \"*/*\"),  # Bad 73\n",
    "    (\"../cache/data/DIRE/test/lsun_bedroom/sdv1_new\", 2, \"*\"),\n",
    "    (\"../cache/data/FakeImageDataset/ImageData/val/SDv15-CC30K/SDv15-CC30K\", 2, \"*/*\"),\n",
    "    # Label 3\n",
    "    (\"../cache/data/DIRE/test/lsun_bedroom/sdv2\", 2, \"*\"),\n",
    "    (\"../cache/data/DIRE/test/celebahq/sdv2\", 2, \"*\"),\n",
    "    (\"../cache/data/FakeImageDataset/ImageData/val/SDv21-CC15K/SDv21-CC15K/SDv2-dpmsolver-25-10K\", 2, \"*\"),  # Bad 79\n",
    "    # Label 4\n",
    "    (\"../cache/data/FakeImageDataset/ImageData/val/Midjourneyv5-5K/Midjourneyv5-5K_test\", 3, \"*\"),  # Bad  65\n",
    "    (\"../cache/data/DIRE/test/lsun_bedroom/midjourney\", 3, \"*\"),  # Bad < 13\n",
    "    # # AI Artbench Dataset\n",
    "    # (\"../cache/data/ai-artbench/test/AI*\", 1.0, \"*\", TEST_SHARDS, 0),  # 675 Batches\n",
    "    # (\"../cache/data/ai-artbench/test/real\", 0.0, \"*/*\", TEST_SHARDS, 0),\n",
    "    # # CIFAKE Dataset\n",
    "    # (\"../cache/data/FakeImageDataset/ImageData/val/cogview2-22K/cogview2-22K\", 1.0, \"*\", TEST_SHARDS, 0),\n",
    "    # DIRE Imagenet Dataset\n",
    "    # (\"../cache/data/DIRE/test/celebahq/if\", 1.0, \"*\", TEST_SHARDS, 0),\n",
    "    # (\"../cache/data/DIRE/test/celebahq/dalle2\", 1.0, \"*\", TEST_SHARDS, 0),\n",
    "    # # DIRE Lsun Bedroom Dataset\n",
    "    # (\"../cache/data/DIRE/test/lsun_bedroom/dalle2\", 1.0, \"*\", TEST_SHARDS, 0),\n",
    "    # (\"../cache/data/DIRE/test/lsun_bedroom/vqdiffusion\", 1.0, \"*\", TEST_SHARDS, 0),\n",
    "    # FakeImageDataset\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading and Tranformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image):\n",
    "    image = tf.image.resize_with_pad(\n",
    "        image=image,\n",
    "        target_height=CONFIGURATION[\"IM_SIZE\"],\n",
    "        target_width=CONFIGURATION[\"IM_SIZE\"],\n",
    "    )\n",
    "    # divide by 255 to normalize\n",
    "    image = image / 255.0\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "    img = tf.io.decode_image(img, channels=3)\n",
    "    return resize_image(img)\n",
    "\n",
    "\n",
    "def process_path(file_path):\n",
    "    # Load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "# write a function apply Fourier Transform to the image and return the image\n",
    "def apply_fourier_transform(image):\n",
    "    # print(f\"Image shape: {image.shape}\")\n",
    "    # extract r channel from the image\n",
    "    r = image[:, :, 0]\n",
    "    # extract g channel from the image\n",
    "    g = image[:, :, 1]\n",
    "    # extract b channel from the image\n",
    "    b = image[:, :, 2]\n",
    "\n",
    "    # apply fourier transform to the image\n",
    "    r = tf.signal.fft2d(tf.cast(r, dtype=tf.complex64))\n",
    "    g = tf.signal.fft2d(tf.cast(g, dtype=tf.complex64))\n",
    "    b = tf.signal.fft2d(tf.cast(b, dtype=tf.complex64))\n",
    "    # # shift the zero-frequency component to the center of the spectrum\n",
    "    r = tf.signal.fftshift(r)\n",
    "    g = tf.signal.fftshift(g)\n",
    "    b = tf.signal.fftshift(b)\n",
    "    # apply log to the image enhance the magnitude of the image and to reduce the dynamic range of the data for visualization\n",
    "    r = 20 * tf.math.log(tf.abs(r) + 1)\n",
    "    g = 20 * tf.math.log(tf.abs(g) + 1)\n",
    "    b = 20 * tf.math.log(tf.abs(b) + 1)\n",
    "    # normalize the value using min-max normalization\n",
    "    r = (r - tf.reduce_min(r)) / (tf.reduce_max(r) - tf.reduce_min(r))\n",
    "    g = (g - tf.reduce_min(g)) / (tf.reduce_max(g) - tf.reduce_min(g))\n",
    "    b = (b - tf.reduce_min(b)) / (tf.reduce_max(b) - tf.reduce_min(b))\n",
    "    # merge channels\n",
    "    if CONFIGURATION[\"CHANNELS\"] == 6:\n",
    "        o_r = image[:, :, 0]\n",
    "        o_g = image[:, :, 1]\n",
    "        o_b = image[:, :, 2]\n",
    "        image = tf.stack([o_r, o_g, o_b, r, g, b], axis=-1)\n",
    "    else:\n",
    "        image = tf.stack([r, g, b], axis=-1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize_dataset(samples):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    index = 1\n",
    "    for image, label in samples:\n",
    "        plt.subplot(4, 4, index)\n",
    "        plt.imshow(image)\n",
    "        title = CONFIGURATION[\"CLASS_NAMES\"][int(label)]\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        index += 1\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_custom_dataset2(directory, label, pattern):\n",
    "    # if directory path contains 'aiornot' load it as tf dataset else load it as a custom dataset\n",
    "    directory = directory.decode(\"utf-8\")\n",
    "    pattern = pattern.decode(\"utf-8\")\n",
    "\n",
    "    if \"aiornot\" in directory:\n",
    "        read_aiornot = load_from_disk(dataset_path=directory)\n",
    "        dataset = read_aiornot.to_tf_dataset(\n",
    "            columns=\"image\",\n",
    "            label_cols=\"label\",\n",
    "        )\n",
    "        dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32), y))\n",
    "        dataset = dataset.map(lambda x, y: (resize_image(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    else:\n",
    "        list_ds = tf.data.Dataset.list_files(str(Path(directory) / pattern), shuffle=True)\n",
    "        dataset = list_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.map(lambda x: (x, label))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_dataset2(directory, pattern):\n",
    "    pattern = tf.strings.join([directory, pattern], separator=\"/\")\n",
    "    dataset = tf.data.TFRecordDataset.list_files(pattern, shuffle=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Dataset Creation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wds_prefix = Path(\"../cache/wds/\")\n",
    "# create the directory if it does not exist\n",
    "wds_prefix.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# test_directory_index = 1\n",
    "# dataset = get_dataset2(TEST_DIRECTORIES[test_directory_index][0], TEST_DIRECTORIES[test_directory_index][2])\n",
    "# labelled_dataset = dataset.map(lambda file_path: (file_path, TEST_DIRECTORIES[test_directory_index][1]))\n",
    "# images_dataset = labelled_dataset.map(\n",
    "#     lambda image, label: (process_path(image), label),\n",
    "#     num_parallel_calls=tf.data.AUTOTUNE\n",
    "# )\n",
    "\n",
    "\n",
    "# tar_file_path = str(wds_prefix / f\"test_{test_directory_index}_dataset.tar\")\n",
    "# sink = wds.TarWriter(tar_file_path)\n",
    "# for index, (input, output) in enumerate(images_dataset):\n",
    "#     if index%1000==0:\n",
    "#         print(f\"{index:6d}\", end=\"\\r\", flush=True, file=sys.stderr)\n",
    "#     # conver input to numpy array\n",
    "#     input = input.numpy()\n",
    "#     output = output\n",
    "\n",
    "#     sink.write({\n",
    "#         \"__key__\": \"sample%06d\" % index,\n",
    "#         \"input.pyd\": input,\n",
    "#         \"output.pyd\": output,\n",
    "#     })\n",
    "# sink.close()\n",
    "\n",
    "for test_directory in TEST_DIRECTORIES:\n",
    "    directory_path = test_directory[0].replace(\"../cache/data\", \"\")\n",
    "    test_dataset_name = (\n",
    "        directory_path.split(\"/\")[1] + \"_\" + directory_path.split(\"/\")[-2] + \"_\" + directory_path.split(\"/\")[-1]\n",
    "    )\n",
    "\n",
    "    dataset = get_dataset2(test_directory[0], test_directory[2])\n",
    "    labelled_dataset = dataset.map(lambda file_path: (file_path, test_directory[1]))\n",
    "    images_dataset = labelled_dataset.map(\n",
    "        lambda image, label: (process_path(image), label), num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    tar_file_path = str(wds_prefix / f\"test_{test_dataset_name}.tar\")\n",
    "    sink = wds.TarWriter(tar_file_path)\n",
    "    for index, (input, output) in enumerate(images_dataset):\n",
    "        if index % 1000 == 0:\n",
    "            print(f\"{index:6d}\", end=\"\\r\", flush=True, file=sys.stderr)\n",
    "        # conver input to numpy array\n",
    "        input = input.numpy()\n",
    "        output = output\n",
    "\n",
    "        sink.write(\n",
    "            {\n",
    "                \"__key__\": \"sample%06d\" % index,\n",
    "                \"input.pyd\": input,\n",
    "                \"output.pyd\": output,\n",
    "            }\n",
    "        )\n",
    "    sink.close()\n",
    "    log.info(f\"Test dataset {test_dataset_name} created locally {tar_file_path}\")\n",
    "\n",
    "    # # upload the generated tar file to s3 bucket using s3 sdk\n",
    "    # key = PREFIX + tar_file_path.split(\"/\")[-1]\n",
    "    # s3_client.upload_file(\n",
    "    #     Filename = tar_file_path,\n",
    "    #     Bucket = S3_BUCKET,\n",
    "    #     Key = key\n",
    "    # )\n",
    "\n",
    "    log.info(f\"Test dataset {test_dataset_name} uploaded at {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataset = wds.WebDataset('https://mp-ml-data-dev.s3.us-west-2.amazonaws.com/finder/ai_or_not/ai_or_not_datasets/webdatasets/test_1_dataset.tar')\n",
    "\n",
    "# samples = islice(dataset, 0, 16)\n",
    "# images = []\n",
    "# for sample in samples:\n",
    "#     # print(sample.keys())\n",
    "#     # print(sample[\"input.pyd\"])\n",
    "#     # read pickle data\n",
    "#     image_numpy_array = pickle.loads(sample[\"input.pyd\"])\n",
    "#     label = pickle.loads(sample[\"output.pyd\"])\n",
    "#     # print(image_numpy_array.shape)\n",
    "#     images.append((image_numpy_array, label))\n",
    "\n",
    "\n",
    "# visualize_dataset(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFS3Dataset:\n",
    "    \"\"\"This class is a convenient placeholder for the dataset-related information.\n",
    "    You could also just define these iterator etc. as global functions.\"\"\"\n",
    "\n",
    "    def __init__(self, prefix, files):\n",
    "        self.length = 200_000\n",
    "        self.urls = []\n",
    "        for f in files:\n",
    "            self.urls.append(prefix + f)\n",
    "        self.dataset = self.get_s3_dataset(self.urls)\n",
    "        self.loader = multi.MultiLoader(self.dataset, workers=12)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for sample in self.loader:\n",
    "            yield pickle.loads(sample[\"input.pyd\"]), pickle.loads(sample[\"output.pyd\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def get_s3_dataset(self, urls):\n",
    "        # add awscli command to urls\n",
    "        urls = [f\"pipe:aws s3 cp {url} -\" for url in urls]\n",
    "        dataset = wds.WebDataset(urls, shardshuffle=True)\n",
    "        return dataset\n",
    "\n",
    "    def output_shapes(self):\n",
    "        return ((128, 128, 3), ())\n",
    "\n",
    "    def output_types(self):\n",
    "        return (tf.float32, tf.int64)\n",
    "\n",
    "\n",
    "s3_dataset_url = \"s3://mp-ml-data-dev/finder/ai_or_not/ai_or_not_datasets/webdatasets/test_7_dataset.tar\"\n",
    "\n",
    "# list all files in S3_PREFIX directory\n",
    "s3_dataset_files = s3_client.list_objects_v2(Bucket=S3_BUCKET, Prefix=PREFIX)\n",
    "# get all files from the response\n",
    "s3_dataset_files = s3_dataset_files[\"Contents\"]\n",
    "# get the file names\n",
    "s3_dataset_files = [file[\"Key\"] for file in s3_dataset_files]\n",
    "# remove the directory name from the file names\n",
    "s3_dataset_files = [file.replace(PREFIX, \"\") for file in s3_dataset_files]\n",
    "# remove the empty string from the list\n",
    "s3_dataset_files = list(filter(None, s3_dataset_files))\n",
    "# log the number of files\n",
    "log.info(f\"Number of files in the dataset: {s3_dataset_files}\")\n",
    "\n",
    "tf_s3_dataset = TFS3Dataset(prefix=S3_PREFIX, files=s3_dataset_files)\n",
    "\n",
    "\n",
    "tdf = tf.data.Dataset.from_generator(\n",
    "    generator=tf_s3_dataset.__iter__,\n",
    "    output_types=tf_s3_dataset.output_types(),\n",
    "    output_shapes=tf_s3_dataset.output_shapes(),\n",
    ")\n",
    "\n",
    "\n",
    "visualize_dataset(tdf.take(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a keras model from directory\n",
    "model = tf.keras.models.load_model(\n",
    "    \"/Users/skoneru/workspace/discovery/playground/ai_or_not/cache/models/model_ev2s_99_acc_rgb/saved_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(tdf.batch(64), verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
