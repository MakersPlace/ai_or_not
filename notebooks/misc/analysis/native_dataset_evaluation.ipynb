{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as log\n",
    "import pickle\n",
    "from itertools import chain\n",
    "from multiprocessing import Lock, RawValue\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import srsly\n",
    "import tensorflow as tf\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "logger = log.getLogger()\n",
    "logger.setLevel(log.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boto3 session using profile name 'prod'\n",
    "session = boto3.Session(profile_name=\"production\")\n",
    "# create s3 client using session\n",
    "s3_client = session.client(\"s3\")\n",
    "\n",
    "S3_BUCKET = \"makersdistillery\"\n",
    "S3_FULL_PREFIX_PATH = f\"finder/media_to_index/full\"\n",
    "GENRES_DATASETS_PATH = Path(\"cache/genres_dataset\")\n",
    "GENRES_SENTENCES_FILE_PATH = GENRES_DATASETS_PATH / \"genre_sentences.pickle\"\n",
    "FILTERED_NFTS_FILE_PATH = GENRES_DATASETS_PATH / \"filtered_nfts.pickle\"\n",
    "FILTERED_NFTS_METADATA_FILE_PATH = GENRES_DATASETS_PATH / \"filtered_nfts_metadat.json\"\n",
    "\n",
    "SENTENCES_LIMIT = 3\n",
    "GENRES_LIMIT = 3\n",
    "\n",
    "LIMIT = 1_000\n",
    "CLEAN_RUN = True\n",
    "\n",
    "CACHE_DIR = Path(\"cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "GENRES_DATASETS_PATH.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_text = \"\"\"\n",
    "3D\n",
    "Abstract\n",
    "AI Generated Art\n",
    "Generative Art\n",
    "Animation\n",
    "Black and White\n",
    "Calligraphic\n",
    "Collage Art\n",
    "Color Field\n",
    "Comic/Cartoon\n",
    "Conceptual Art\n",
    "Crypto Art\n",
    "Dance\n",
    "Dark\n",
    "Digital Art\n",
    "Digital Culture\n",
    "Drawing\n",
    "Ephemera\n",
    "Fantasy\n",
    "Fashion\n",
    "Feminist\n",
    "Figurative\n",
    "Film/Video\n",
    "Fine art\n",
    "Folk Art\n",
    "Glitch Art\n",
    "Gothic Art\n",
    "Graffiti/Street Art\n",
    "Hyperrealism\n",
    "Illustration\n",
    "Immersive\n",
    "Interactive\n",
    "Landscape\n",
    "Light Art\n",
    "Mixed Media\n",
    "Monochrome\n",
    "Multi-media\n",
    "Music\n",
    "Nature\n",
    "Net Art\n",
    "Painting\n",
    "Photography\n",
    "Phygitals\n",
    "Pixel art\n",
    "Pop Art\n",
    "Portrait\n",
    "Psychedelic Art\n",
    "science fiction\n",
    "Sculpture\n",
    "Sports\n",
    "Surreal\"\"\"\n",
    "# convert above text to list of strings\n",
    "GENRES = [x.strip().lower() for x in genres_text.split(\"\\n\") if x.strip() != \"\"]\n",
    "# sorts list\n",
    "GENRES.sort()\n",
    "\n",
    "# generate GENRES ids array\n",
    "GENRE_IDS = list(range(len(GENRES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_files_from_s3(s3_client, s3_prefix, file_name, limit=1):\n",
    "    \"\"\"\n",
    "    This function is used to get the latest file from s3 directory and download latest file locally and return the local path\n",
    "    \"\"\"\n",
    "    log.info(f\"Getting latest file from s3 bucket: {S3_BUCKET} and prefix: {s3_prefix}\")\n",
    "    response = s3_client.list_objects_v2(Bucket=S3_BUCKET, Prefix=s3_prefix)\n",
    "    # log total response count\n",
    "    log.info(f\"Total files fetched are {len(response['Contents'])}\")\n",
    "\n",
    "    # filter out files matching the file name\n",
    "    matching_files = [file for file in response[\"Contents\"] if Path(file[\"Key\"]).name == file_name]\n",
    "    log.info(f\"Found {len(matching_files)} files matching the file name: {file_name}\")\n",
    "    # Sort files by last modified date, to get the latest file first\n",
    "    matching_files.sort(key=lambda x: x[\"LastModified\"], reverse=True)\n",
    "    log.info(f\"Sorted files by last modified date {matching_files}\")\n",
    "    # Pick the latest n(limit) files\n",
    "    latest_files = matching_files[:limit]\n",
    "    # Sort files by last modified date to get the latest file last.\n",
    "    # This sorting is needed to preserve the updates order\n",
    "    latest_files.sort(key=lambda x: x[\"LastModified\"])\n",
    "    log.info(f\"Latest {len(latest_files)} files: {latest_files}\")\n",
    "\n",
    "    if len(latest_files) == 0:\n",
    "        log.error(f\"File {file_name} not found in s3 bucket: {S3_BUCKET} and prefix: {s3_prefix}\")\n",
    "        return []\n",
    "\n",
    "    # Iterate on latest files and Download latest file locally\n",
    "    local_file_paths = []\n",
    "    for latest_file in latest_files:\n",
    "        prefix_path = latest_file[\"Key\"]\n",
    "        # extract last 2 parts in prefix path as file name\n",
    "        local_file_name = prefix_path.split(\"/\")[-2] + \"_\" + prefix_path.split(\"/\")[-1]\n",
    "        local_file_path = CACHE_DIR / local_file_name\n",
    "        # Download file only if it does not exist locally\n",
    "        if not local_file_path.exists():\n",
    "            log.info(f\"Downloading latest file: {prefix_path} to local path: {local_file_path}\")\n",
    "            s3_client.download_file(S3_BUCKET, latest_file[\"Key\"], local_file_path)\n",
    "            log.info(f\"Downloaded latest file: {prefix_path} to local path: {local_file_path}\")\n",
    "        local_file_paths.append(local_file_path)\n",
    "\n",
    "    log.info(f\"Local file paths: {local_file_paths}\")\n",
    "\n",
    "    return local_file_paths\n",
    "\n",
    "\n",
    "def get_s3_file_url(s3_file_name):\n",
    "    return f\"https://makersdistillery.s3.us-west-2.amazonaws.com/1000x/{s3_file_name}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latest file from s3\n",
    "local_file_paths = get_latest_files_from_s3(s3_client, S3_FULL_PREFIX_PATH, \"data.jsonl\", limit=1)\n",
    "# Read jsonl file\n",
    "log.info(f\"Reading jsonl files: {local_file_paths}\")\n",
    "# Read all jsonl files as iterators and chain them together\n",
    "json_data_iterator = chain(*[srsly.read_jsonl(local_path) for local_path in local_file_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "SENTENCES_FILTER_MODEL_ID = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "GENRE_MATCH_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "sentence_filter_model = SentenceTransformer(SENTENCES_FILTER_MODEL_ID, device=\"mps\")\n",
    "genre_match_model = SentenceTransformer(GENRE_MATCH_MODEL_ID, device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_pickle_file(dict_to_save, pickle_file_path):\n",
    "    # delete file if exists\n",
    "    if pickle_file_path.exists():\n",
    "        pickle_file_path.unlink()\n",
    "\n",
    "    with open(pickle_file_path, \"wb\") as f:\n",
    "        pickle.dump(dict_to_save, f)\n",
    "\n",
    "\n",
    "def read_dict_from_pickle_file(pickle_file_path):\n",
    "    with open(pickle_file_path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUERY = \"What is the Genre of Art?\"\n",
    "QUERY = \"What is the Art category or Genre or style?\"\n",
    "QUERY_EMBED = sentence_filter_model.encode(QUERY, show_progress_bar=False)\n",
    "\n",
    "\n",
    "def get_genre_sentence(text):\n",
    "    # split text into sentences\n",
    "    raw_sentences = text.strip().split(\".\")\n",
    "    # remove sentences with no text\n",
    "    cleaned_sentences = [sentence.strip() for sentence in raw_sentences if sentence.strip() != \"\"]\n",
    "\n",
    "    if len(cleaned_sentences) == 0:\n",
    "        return [], [], []\n",
    "\n",
    "    sentence_embeddings = sentence_filter_model.encode(cleaned_sentences, show_progress_bar=False)\n",
    "\n",
    "    # Compute dot score between query and all document embeddings\n",
    "    scores = util.cos_sim(QUERY_EMBED, sentence_embeddings)[0].cpu().tolist()\n",
    "\n",
    "    # Combine docs & scores\n",
    "    sentences_and_scores = list(zip(cleaned_sentences, scores, sentence_embeddings))\n",
    "\n",
    "    logger.debug(f\"Sentences and Scores: {sentences_and_scores}\")\n",
    "\n",
    "    # Sort by decreasing score\n",
    "    sorted_sentences_and_scores = sorted(sentences_and_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # return top 3 if available\n",
    "    filtered_doc_score_pairs = (\n",
    "        sorted_sentences_and_scores[:SENTENCES_LIMIT]\n",
    "        if len(sorted_sentences_and_scores) >= SENTENCES_LIMIT\n",
    "        else sorted_sentences_and_scores\n",
    "    )\n",
    "\n",
    "    # split sentence, score and embedding\n",
    "    sentences, scores, embeddings = zip(*filtered_doc_score_pairs)\n",
    "\n",
    "    return sentences, scores, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_sentences = {}\n",
    "\n",
    "item_coumt = 0\n",
    "\n",
    "\n",
    "if not Path(GENRES_SENTENCES_FILE_PATH).exists() or CLEAN_RUN:\n",
    "    log.info(\"Creating genre_sentences file\")\n",
    "\n",
    "    for data in json_data_iterator:\n",
    "        if item_coumt == LIMIT:\n",
    "            break\n",
    "\n",
    "        log.debug(f\"Processing data: {data}\")\n",
    "        id = data[\"_id\"]\n",
    "        # rewrite above line with corrected f string\n",
    "        text = f\"{data['_source']['title']} {data['_source']['description']}\"\n",
    "\n",
    "        # check if tags key exists in data\n",
    "        if \"tags\" in data[\"_source\"]:\n",
    "            tags = data[\"_source\"][\"tags\"]\n",
    "        else:\n",
    "            tags = []\n",
    "\n",
    "        preview_file_name = data[\"_source\"][\"finder_data\"][\"s3_preview_filename\"]\n",
    "\n",
    "        sentences, scores, embeddings = get_genre_sentence(text)\n",
    "\n",
    "        log.debug(f\"Result: {sentences, scores, embeddings}\")\n",
    "\n",
    "        genre_sentences[id] = {\n",
    "            \"text\": text,\n",
    "            \"tags\": tags,\n",
    "            \"genre_sentences\": sentences,\n",
    "            \"genre_sentences_scores\": scores,\n",
    "            \"genre_sentences_embeddings\": embeddings,\n",
    "            \"preview_file_name\": preview_file_name,\n",
    "        }\n",
    "\n",
    "        item_coumt += 1\n",
    "\n",
    "        if item_coumt % 1000 == 0:\n",
    "            log.info(f\"Processed {item_coumt} items\")\n",
    "            save_dict_to_pickle_file(genre_sentences, GENRES_SENTENCES_FILE_PATH)\n",
    "\n",
    "\n",
    "else:\n",
    "    log.info(\"Reading genre_sentences file\")\n",
    "    genre_sentences = read_dict_from_pickle_file(GENRES_SENTENCES_FILE_PATH)\n",
    "\n",
    "save_dict_to_pickle_file(genre_sentences, GENRES_SENTENCES_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_embeddings = genre_match_model.encode(GENRES, show_progress_bar=False)\n",
    "log.info(f\"genre_embeddings: {len(genre_embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_names(genre_ids):\n",
    "    return [GENRES[genre_id] for genre_id, _ in genre_ids]\n",
    "\n",
    "\n",
    "def get_genres(text_array):\n",
    "    if len(text_array) == 0:\n",
    "        return []\n",
    "\n",
    "    text_embeddings = genre_match_model.encode(text_array, show_progress_bar=False)\n",
    "\n",
    "    genre_scores = util.cos_sim(genre_embeddings, text_embeddings).cpu().tolist()\n",
    "\n",
    "    log.debug(f\"All genre_scores: {(genre_scores)}\")\n",
    "    genre_scores = [max(scores) for scores in genre_scores]\n",
    "\n",
    "    # Combine docs & scores\n",
    "    genre_scores = list(zip(GENRE_IDS, genre_scores))\n",
    "\n",
    "    logger.debug(f\"Genre Scores: {genre_scores}\")\n",
    "\n",
    "    # Sort by decreasing score\n",
    "    sorted_genres = sorted(genre_scores, key=lambda x: x[1], reverse=True)\n",
    "    log.debug(f\"Sorted genre_scores: {(sorted_genres)}\")\n",
    "\n",
    "    # restrict genre scores to 2 decimal places\n",
    "    rounded_genres = [(score[0], np.round(score[1], 2)) for score in sorted_genres]\n",
    "    log.debug(f\"Rounded genre_scores: {(rounded_genres)}\")\n",
    "\n",
    "    # return top 3 if available\n",
    "    filtered_sorted_genres = rounded_genres[:GENRES_LIMIT] if len(rounded_genres) >= GENRES_LIMIT else rounded_genres\n",
    "\n",
    "    # log.debug(f\"Top {GENRES_LIMIT} genres for {key}: {genre_sentences[key]['genres']} Preview: {get_s3_file_url(value['preview_file_name'])}\")\n",
    "\n",
    "    return filtered_sorted_genres\n",
    "\n",
    "\n",
    "for key, value in genre_sentences.items():\n",
    "    # log.info(f\"key: {key}, value: {value}\")\n",
    "    genre_sentences_text = value[\"genre_sentences\"]\n",
    "\n",
    "    if len(genre_sentences_text) == 0:\n",
    "        continue\n",
    "\n",
    "    text_genres = get_genres(genre_sentences_text)\n",
    "\n",
    "    genre_sentences[key][\"text_genre_scores\"] = text_genres\n",
    "\n",
    "    log.debug(\n",
    "        f\"Text Top {GENRES_LIMIT} for {key}: {get_genre_names(text_genres)} Preview: {get_s3_file_url(value['preview_file_name'])}\"\n",
    "    )\n",
    "\n",
    "    tags = value[\"tags\"]\n",
    "    if len(tags) == 0:\n",
    "        continue\n",
    "\n",
    "    tags_genres = get_genres(tags)\n",
    "\n",
    "    genre_sentences[key][\"tags_genre_scores\"] = tags_genres\n",
    "\n",
    "    log.debug(\n",
    "        f\"Tags Top {GENRES_LIMIT} for {key}: {get_genre_names(tags_genres)} Preview: {get_s3_file_url(value['preview_file_name'])}\"\n",
    "    )\n",
    "\n",
    "    log.debug(\n",
    "        f\"Top {GENRES_LIMIT} for {key}: Text: {get_genre_names(text_genres)} Genre Tags: {get_genre_names(tags_genres)} User Tags: {tags} Preview: {get_s3_file_url(value['preview_file_name'])}\"\n",
    "    )\n",
    "\n",
    "\n",
    "save_dict_to_pickle_file(genre_sentences, GENRES_SENTENCES_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log all genres along with their respective genre ids\n",
    "for genre_id, genre in enumerate(GENRES):\n",
    "    log.info(f\"{genre_id}: {genre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_GENRE_ID = 41\n",
    "FILTER_GENRE_NAME = GENRES[FILTER_GENRE_ID].strip().lower().replace(\" \", \"_\")\n",
    "display_threshold = 0.9\n",
    "\n",
    "# read pickle file and print preview image urls for genres index 2\n",
    "genre_sentences = read_dict_from_pickle_file(GENRES_SENTENCES_FILE_PATH)\n",
    "\n",
    "filtered_nfts = {}\n",
    "\n",
    "\n",
    "def filter_genre(genre_id, threshold):\n",
    "    # Filter and print preview image urls for genres index 2\n",
    "    for key, value in genre_sentences.items():\n",
    "        genre_scores = []\n",
    "        # check if genre_scores key exists in value\n",
    "        if \"text_genre_scores\" in value and len(value[\"text_genre_scores\"]) != 0:\n",
    "            genre_scores.extend(value[\"text_genre_scores\"])\n",
    "\n",
    "        if \"tags_genre_scores\" in value and len(value[\"tags_genre_scores\"]) != 0:\n",
    "            genre_scores.extend(value[\"tags_genre_scores\"])\n",
    "\n",
    "        if len(genre_scores) == 0:\n",
    "            continue\n",
    "\n",
    "        # Filter genre scores for genre id\n",
    "        genre_scores = [score[1] for score in genre_scores if score[0] == genre_id]\n",
    "\n",
    "        # check if any genre scores is greater than threshold\n",
    "        if len(genre_scores) == 0 or max(genre_scores) < threshold:\n",
    "            continue\n",
    "\n",
    "        log.debug(f\"genre_scores: {(genre_scores)}\")\n",
    "\n",
    "        # print preview image urls and score\n",
    "        # log.info(f\"{GENRES[FILTER_GENRE_ID]} Score: {genre_scores[0]} Preview: {get_s3_file_url(value['preview_file_name'])} Description: {value['text']} \")\n",
    "\n",
    "        filtered_nfts[key] = value\n",
    "\n",
    "\n",
    "filter_genre(FILTER_GENRE_ID, display_threshold)\n",
    "\n",
    "# save filtered nfts to pickle file\n",
    "save_dict_to_pickle_file(filtered_nfts, FILTERED_NFTS_FILE_PATH)\n",
    "metadata = [\n",
    "    {\n",
    "        \"genre\": GENRES[FILTER_GENRE_ID],\n",
    "        \"genre_id\": FILTER_GENRE_ID,\n",
    "        \"threshold\": display_threshold,\n",
    "        \"count\": len(filtered_nfts),\n",
    "        \"sentence_limit\": SENTENCES_LIMIT,\n",
    "        \"genre_limit\": GENRES_LIMIT,\n",
    "        \"sentence_filter_model\": SENTENCES_FILTER_MODEL_ID,\n",
    "        \"genre_match_model\": GENRE_MATCH_MODEL_ID,\n",
    "    }\n",
    "]\n",
    "srsly.write_jsonl(FILTERED_NFTS_METADATA_FILE_PATH, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print filtered nfts along with their genre , score, preview image url and description\n",
    "for key, value in filtered_nfts.items():\n",
    "    text_genre_scores = []\n",
    "    text_genre_ids = []\n",
    "    tags_genre_ids = []\n",
    "    # check if genre_scores key exists in value\n",
    "    if \"text_genre_scores\" in value and len(value[\"text_genre_scores\"]) != 0:\n",
    "        text_genre_scores.extend(value[\"text_genre_scores\"])\n",
    "        text_genre_ids = [score[0] for score in value[\"text_genre_scores\"]]\n",
    "\n",
    "    tags_genre_scores = []\n",
    "    if \"tags_genre_scores\" in value and len(value[\"tags_genre_scores\"]) != 0:\n",
    "        tags_genre_scores.extend(value[\"tags_genre_scores\"])\n",
    "        tags_genre_ids = [score[0] for score in value[\"tags_genre_scores\"]]\n",
    "\n",
    "    # find common genre ids between text and tags\n",
    "    common_genre_ids = set(text_genre_ids).intersection(tags_genre_ids)\n",
    "\n",
    "    log.info(\n",
    "        f\"\"\"\n",
    "{GENRES[FILTER_GENRE_ID]} Common Genres: {common_genre_ids}  Text Genre Scores: {text_genre_scores}  Tags Genre Scores: {tags_genre_scores} Preview: {get_s3_file_url(value['preview_file_name'])} \n",
    "             Genre Sentences: {value['genre_sentences']} \"\"\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
