{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging as log\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from io import BytesIO\n",
    "from time import sleep\n",
    "\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from botocore.config import Config\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "log.basicConfig(stream=sys.stdout, level=log.INFO)\n",
    "\n",
    "# Create AWS session token\n",
    "session = boto3.Session(profile_name=\"dev\")\n",
    "client_config = Config(max_pool_connections=1280)\n",
    "s3_client = session.client(\"s3\", config=client_config)\n",
    "BUCKET = \"S3_BUCKET\"\n",
    "PREFIX = \"finder/ai_or_not/ai_or_not_datasets\"\n",
    "\n",
    "MAX_ITEMS = 8\n",
    "BATCH_SIZE = 4\n",
    "IM_SIZE = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "TRAIN_DIRECTORIES = [\n",
    "    # Label 0\n",
    "    (\"DIRE/train/imagenet/real\", 0, \"*/*\"),\n",
    "    (\"DIRE/train/celebahq/real\", 0, \"*\"),\n",
    "    (\"DIRE/train/lsun_bedroom/real\", 0, \"*\"),\n",
    "    (\"cifake/train/REAL\", 0, \"*\"),\n",
    "    # Label 1\n",
    "    (\"DIRE/train/imagenet/adm\", 1, \"*/*\"),\n",
    "    (\"DIRE/train/lsun_bedroom/adm\", 1, \"*\"),\n",
    "    # Label 2\n",
    "    (\"cifake/train/FAKE\", 2, \"*\"),  # Generated by SD 1.4\n",
    "    (\n",
    "        \"FakeImageDataset/ImageData/train/SDv15R-CC1M/SDv15R-dpmsolver-25-1M/SDv15R-CC1M\",\n",
    "        2,\n",
    "        \"*\",\n",
    "    ),  # Generated by SD 1.5\n",
    "    (\"DIRE/train/celebahq/sdv2\", 2, \"*/*\"),\n",
    "    # Label 3\n",
    "    (\"FakeImageDataset/ImageData/val/Midjourneyv5-5K/Midjourneyv5-5K_train\", 3, \"*\"),\n",
    "]\n",
    "\n",
    "# extensions to filter oout\n",
    "UNWANTED_FILE_EXTENSIONS = [\"tar\", \"gz\", \"zip\", \"DS_Store\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(keys, labels):\n",
    "    def _download_image(key, label):\n",
    "        key = key.decode(\"utf-8\")\n",
    "        log.debug(f\"Key to download: {key}\")\n",
    "        response = s3_client.get_object(Bucket=BUCKET, Key=key)\n",
    "        body = response[\"Body\"]\n",
    "        bytes = body.read()\n",
    "        # convert to PIL image\n",
    "        image = Image.open(BytesIO(bytes))\n",
    "        # restrict to 3 channels\n",
    "        image = image.convert(\"RGB\")\n",
    "        # Expand or shrink the image to fit\n",
    "        contained_image = ImageOps.contain(image, (IM_SIZE, IM_SIZE))\n",
    "        # pad the image\n",
    "        padded_image = ImageOps.pad(contained_image, (IM_SIZE, IM_SIZE), color=0)\n",
    "        # convert to numpy array\n",
    "        image_array = np.array(padded_image)\n",
    "        # normalize the image\n",
    "        normalized_image = image_array / 255.0\n",
    "        log.debug(f\"Normalized Image Shape: {normalized_image.shape}\")\n",
    "        return normalized_image, label\n",
    "\n",
    "    log.debug(f\"Keys: {keys.shape} Labels: {labels.shape}\")\n",
    "    keys = keys.numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "    # thread pool executor to download images in parallel\n",
    "    with ThreadPoolExecutor(max_workers=BATCH_SIZE) as executor:\n",
    "        results = list(executor.map(_download_image, keys, labels))\n",
    "\n",
    "    # convert to numpy array\n",
    "    images, labels = zip(*results)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    log.debug(f\"Images Shape: {images.shape}\")\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def read_s3_image(prefix, label):\n",
    "    prefix = prefix.decode(\"utf-8\")\n",
    "    s3_paginator = s3_client.get_paginator(\"list_objects_v2\")\n",
    "    s3_iterator = s3_paginator.paginate(\n",
    "        Bucket=BUCKET, Prefix=prefix, PaginationConfig={\"MaxItems\": MAX_ITEMS, \"PageSize\": BATCH_SIZE}\n",
    "    )\n",
    "    for page in s3_iterator:\n",
    "        raw_keys = []\n",
    "        for item in page[\"Contents\"]:\n",
    "            key = item[\"Key\"]\n",
    "            raw_keys.append(key)\n",
    "\n",
    "        # filter out filders and unwanted file extensions\n",
    "        keys = []\n",
    "        for key in raw_keys:\n",
    "            key_parts = key.split(\".\")\n",
    "            last_part = key_parts[-1]\n",
    "            last_second_part = key_parts[-2]\n",
    "\n",
    "            is_file_name = key.split(\"/\")[-1]\n",
    "\n",
    "            if (\n",
    "                is_file_name != \"\"\n",
    "                and last_part not in UNWANTED_FILE_EXTENSIONS\n",
    "                and last_second_part not in UNWANTED_FILE_EXTENSIONS\n",
    "            ):\n",
    "                keys.append(key)\n",
    "\n",
    "        # only if there are keys\n",
    "        if len(keys) == 0:\n",
    "            continue\n",
    "\n",
    "        converted_keys = tf.convert_to_tensor(keys)\n",
    "        log.debug(f\"{prefix} : Converted Keys {len(keys)}\")\n",
    "        # convert to tensor of shape (batch_size, 1)\n",
    "        # converted_keys = tf.reshape(converted_keys, (-1, 1))\n",
    "        log.debug(f\"Keys Shape: {converted_keys.shape} {keys}\")\n",
    "        yield converted_keys, tf.constant(label, shape=(len(keys),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directories = []\n",
    "current_labels = []\n",
    "\n",
    "for directory in TRAIN_DIRECTORIES:\n",
    "    current_directories.append(f\"{PREFIX}/{directory[0]}\")\n",
    "    current_labels.append(directory[1])\n",
    "\n",
    "print(current_directories)\n",
    "print(current_labels)\n",
    "# create dataset using the directories and labels\n",
    "directories = tf.data.Dataset.from_tensor_slices((current_directories, current_labels))\n",
    "\n",
    "# directories = tf.data.Dataset.from_tensor_slices(current_directories)\n",
    "files_dataset = directories.interleave(\n",
    "    lambda directory_path, label: tf.data.Dataset.from_generator(\n",
    "        generator=read_s3_image,\n",
    "        args=[directory_path, label],\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.string),\n",
    "            tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "        ),\n",
    "    ),\n",
    "    cycle_length=len(TRAIN_DIRECTORIES),\n",
    "    block_length=2,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "# # unbatched_dataset = files_dataset.flat_map(tf.data.Dataset.from_tensor_slices)\n",
    "#  unbatched_dataset = files_dataset.unbatch()\n",
    "\n",
    "# map keys to download function\n",
    "image_dataset = files_dataset.map(\n",
    "    map_func=lambda image_prefix, label: tf.py_function(\n",
    "        func=download_images,\n",
    "        inp=[image_prefix, label],\n",
    "        Tout=[tf.float32, tf.int32],\n",
    "    ),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "batched_dataset = image_dataset.prefetch(tf.data.AUTOTUNE).unbatch().batch(4)\n",
    "for images, labels in batched_dataset:\n",
    "    log.info(f\"Keys Count: {images.shape} {labels.shape}\")\n",
    "\n",
    "    if images.shape[0] < 4:\n",
    "        continue\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for n in range(4):\n",
    "        ax = plt.subplot(4, 4, n + 1)\n",
    "        plt.imshow(images[n])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # create a tensorflow dataset from the generator\n",
    "# # dataset = tf.data.Dataset.from_generator(\n",
    "# #     generator=s3_generator,\n",
    "# #     # change the output types accordingly\n",
    "# #     output_signature=(\n",
    "# #         tf.TensorSpec(shape=(None,1), dtype=tf.string)\n",
    "# #     )\n",
    "\n",
    "# # )\n",
    "\n",
    "# dataset = get_composite_dataset()\n",
    "\n",
    "# # unbatched_dataset = dataset.flat_map(tf.data.Dataset.from_tensor_slices)\n",
    "# unbatched_dataset = dataset.unbatch()\n",
    "\n",
    "# # map keys to download function\n",
    "# image_dataset = unbatched_dataset.map(\n",
    "#     map_func=lambda image_prefix: tf.py_function(\n",
    "#         func=download_image2,\n",
    "#         inp=[image_prefix],\n",
    "#         Tout=tf.float32,\n",
    "#     ),\n",
    "#     num_parallel_calls=tf.data.AUTOTUNE\n",
    "# )\n",
    "\n",
    "\n",
    "# batched_dataset = image_dataset.prefetch(tf.data.AUTOTUNE).batch(4)\n",
    "# # for images in batched_dataset:\n",
    "# #     log.info(f\"Keys Count: {images.shape}\")\n",
    "\n",
    "# #     if images.shape[0] < 4:\n",
    "# #         continue\n",
    "# #     plt.figure(figsize=(10, 10))\n",
    "# #     for n in range(4):\n",
    "# #         ax = plt.subplot(4, 4, n + 1)\n",
    "# #         plt.imshow(images[n])\n",
    "# #         plt.axis(\"off\")\n",
    "# #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../../cache/data/FakeImageDataset/ImageData/train/SDv15R-CC1M/SDv15R-dpmsolver-25-1M/SDv15R-CC1M\"\n",
    "\n",
    "# # write function to read the images from the local directory\n",
    "# def read_local_image(prefix):\n",
    "#     for root, dirs, files in os.walk(prefix):\n",
    "#         for file in files:\n",
    "#             # print reading path\n",
    "#             log.info(os.path.join(root, file))\n",
    "#             # read the image\n",
    "#             img = Image.open(os.path.join(root, file))\n",
    "\n",
    "# # read_local_image(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataset = tf.data.Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
    "# # dataset2 = tf.data.Dataset.range(7, 12)\n",
    "# # # NOTE: New lines indicate \"block\" boundaries.\n",
    "# # dataset = dataset.interleave(\n",
    "# #     lambda x: dataset2)\n",
    "# # list(dataset.as_numpy_iterator())\n",
    "\n",
    "# # write a generator function that yields the keys and the file objects\n",
    "# def  s3_generator():\n",
    "\n",
    "#     # composite dataset\n",
    "#     for directory in TRAIN_DIRECTORIES:\n",
    "#         directory_path = directory[0]\n",
    "#         aws_prefix = f\"{PREFIX}/{directory_path}\"\n",
    "#         log.debug(f\"Searching for images in {aws_prefix}\")\n",
    "#         # yield the generator\n",
    "#         yield from read_s3_image(aws_prefix)\n",
    "\n",
    "\n",
    "# def  get_composite_dataset():\n",
    "#     # composite dataset\n",
    "#     composite_dataset = None\n",
    "#     datasets = []\n",
    "#     for directory in TRAIN_DIRECTORIES:\n",
    "#         directory_path = directory[0]\n",
    "#         aws_prefix = f\"{PREFIX}/{directory_path}\"\n",
    "#         log.debug(f\"Searching for images in {aws_prefix}\")\n",
    "\n",
    "#         # create a dataset from the generator\n",
    "#         # datasets.append(\n",
    "#         current_dataset = tf.data.Dataset.from_generator(\n",
    "#                 read_s3_image,\n",
    "#                 args=[aws_prefix],\n",
    "#                 output_signature=tf.TensorSpec(shape=(None, 1), dtype=tf.string),\n",
    "#             )\n",
    "#         datasets.append(current_dataset)\n",
    "#         # )\n",
    "#         # if composite_dataset is None:\n",
    "#         #     log.info(f\"Interleaving {aws_prefix}\")\n",
    "#         #     composite_dataset = current_dataset\n",
    "#         # else:\n",
    "#         #     log.info(f\"Interleaving {aws_prefix}\")\n",
    "#         #     composite_dataset = composite_dataset.interleave(\n",
    "#         #         lambda _: current_dataset,\n",
    "#         #         cycle_length=len(TRAIN_DIRECTORIES),\n",
    "#         #         block_length=1\n",
    "#         #     )\n",
    "\n",
    "#     # interleave the datasets in the list of datasets to create a composite dataset\n",
    "#     # composite_dataset = tf.data.Dataset.zip(tuple(datasets)).interleave(\n",
    "#     #     lambda *args: tf.data.Dataset.from_tensor_slices(args).flat_map(\n",
    "#     #         lambda *images: tf.data.Dataset.from_tensor_slices(images)\n",
    "#     #     ),\n",
    "#     #     cycle_length=len(datasets),\n",
    "#     #     block_length=1,\n",
    "#     #     num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "#     # )\n",
    "#     first_dataset = datasets[0]\n",
    "#     second_dataset = datasets[1]\n",
    "\n",
    "#     composite_dataset = second_dataset.interleave(\n",
    "#         lambda _: first_dataset,\n",
    "#         cycle_length=1,\n",
    "#         block_length=1,\n",
    "#         )\n",
    "#     return composite_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
