{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import data_generator from parent directory\n",
    "sys.path.append(\"..\")\n",
    "from training_pipeline.data_generator import preprocess_image\n",
    "from training_pipeline.data_generator import CropType\n",
    "\n",
    "\n",
    "MODEL_PATH = os.path.join(os.getcwd(), \"../cache/keras_model/saved_model_rgb_classifier\")\n",
    "TEST_FILES_METADATA_CSV = \"/Volumes/FD/ai_or_not/data/cifake/test/FAKE_metadata.csv\"\n",
    "\n",
    "REPO_ID = \"ai-or-not/ai-or-not-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
      "  METAL, no compute capability (probably not an Nvidia GPU)\n",
      "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 12:56:20.523890: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2025-01-07 12:56:20.523924: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2025-01-07 12:56:20.523932: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2025-01-07 12:56:20.523961: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-07 12:56:20.523978: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-01-07 12:56:20 WARNING  Mixed precision compatibility check (mixed_float16): WARNING\n",
      "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
      "  METAL, no compute capability (probably not an Nvidia GPU)\n",
      "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "2025-01-07 12:56:47 WARNING  At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "2025-01-07 12:56:54 WARNING  At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# load tensorflow saved model\n",
    "# model = tf.keras.models.load_model(MODEL_PATH)\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# model = tf.saved_model.load(MODEL_PATH)\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "# model =tf.keras.layers.TFSMLayer(MODEL_PATH, call_endpoint=\"serving_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rgb_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " efficientnetv2-s (Function  (None, 7, 7, 1280)        20331360  \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " top_dropout (Dropout)       (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 3843      \n",
      "                                                                 \n",
      " predictions (Activation)    (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20335203 (77.57 MB)\n",
      "Trainable params: 20181331 (76.99 MB)\n",
      "Non-trainable params: 153872 (601.06 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: FAKE/0 (2).jpg Image shape: (224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 12:56:55.517526: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "Prediction: [[2.8153814e-03 6.9535006e-04 9.9648929e-01]] Max: 2\n",
      "File: FAKE/0 (3).jpg Image shape: (224, 224, 3)\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Prediction: [[7.697749e-04 6.727223e-04 9.985575e-01]] Max: 2\n",
      "File: FAKE/0 (4).jpg Image shape: (224, 224, 3)\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Prediction: [[2.6467521e-04 4.1395988e-04 9.9932134e-01]] Max: 2\n",
      "File: FAKE/0 (5).jpg Image shape: (224, 224, 3)\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Prediction: [[1.5719245e-04 6.9890106e-05 9.9977297e-01]] Max: 2\n",
      "File: FAKE/0 (6).jpg Image shape: (224, 224, 3)\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Prediction: [[0.00128217 0.00166088 0.99705696]] Max: 2\n",
      "File: FAKE/0 (7).jpg Image shape: (224, 224, 3)\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Prediction: [[5.199854e-04 6.420963e-04 9.988379e-01]] Max: 2\n",
      "File: FAKE/0 (8).jpg Image shape: (224, 224, 3)\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Prediction: [[0.001379   0.00103081 0.9975902 ]] Max: 2\n",
      "File: FAKE/0 (9).jpg Image shape: (224, 224, 3)\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Prediction: [[0.00428889 0.00113533 0.99457574]] Max: 2\n",
      "File: FAKE/0.jpg Image shape: (224, 224, 3)\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "Prediction: [[0.02382903 0.00507597 0.971095  ]] Max: 2\n",
      "File: FAKE/1 (10).jpg Image shape: (224, 224, 3)\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Prediction: [[2.5855820e-04 3.6533832e-04 9.9937612e-01]] Max: 2\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(TEST_FILES_METADATA_CSV, skiprows=1)\n",
    "test_files = metadata.values\n",
    "test_files = test_files[:10]\n",
    "\n",
    "# extract prefix path from TEST_FILES_METADATA_CSV\n",
    "prefx_path = Path(TEST_FILES_METADATA_CSV).parent\n",
    "for file in test_files:\n",
    "    file = file[0]\n",
    "    image = preprocess_image(\n",
    "        os.path.join(prefx_path, file), \n",
    "        CropType.RESIZE,\n",
    "    )\n",
    "\n",
    "    print(f\"File: {file} Image shape: {image.shape}\")\n",
    "    predictions = model.predict(np.array([image]))\n",
    "    # take the argmax of the predictions\n",
    "    max_index = np.argmax(predictions)\n",
    "\n",
    "    print(f\"Prediction: {predictions} Max: {max_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to huggingface\n",
    "\n",
    "from huggingface_hub import push_to_hub_keras\n",
    "\n",
    "push_to_hub_keras(\n",
    "    model,\n",
    "    repo_id=REPO_ID,\n",
    "    tags=[\"0.1\", \"classification\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b4e5e894544787baab7cd1fe0a6736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import from_pretrained_keras\n",
    "\n",
    "model = from_pretrained_keras(REPO_ID, token=True, force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: FAKE/0 (2).jpg Image shape: (224, 224, 3)\n",
      "Prediction: [[2.8153814e-03 6.9535006e-04 9.9648929e-01]] Max: 2\n",
      "File: FAKE/0 (3).jpg Image shape: (224, 224, 3)\n",
      "Prediction: [[7.697749e-04 6.727223e-04 9.985575e-01]] Max: 2\n",
      "File: FAKE/0 (4).jpg Image shape: (224, 224, 3)\n",
      "Prediction: [[2.6467521e-04 4.1395988e-04 9.9932134e-01]] Max: 2\n",
      "File: FAKE/0 (5).jpg Image shape: (224, 224, 3)\n",
      "Prediction: [[1.5719245e-04 6.9890106e-05 9.9977297e-01]] Max: 2\n",
      "File: FAKE/0 (6).jpg Image shape: (224, 224, 3)\n",
      "Prediction: [[0.00128217 0.00166088 0.99705696]] Max: 2\n",
      "File: FAKE/0 (7).jpg Image shape: (224, 224, 3)\n",
      "Prediction: [[5.199854e-04 6.420963e-04 9.988379e-01]] Max: 2\n",
      "File: FAKE/0 (8).jpg Image shape: (224, 224, 3)\n",
      "Prediction: [[0.001379   0.00103081 0.9975902 ]] Max: 2\n",
      "File: FAKE/0 (9).jpg Image shape: (224, 224, 3)\n",
      "Prediction: [[0.00428889 0.00113533 0.99457574]] Max: 2\n",
      "File: FAKE/0.jpg Image shape: (224, 224, 3)\n",
      "Prediction: [[0.02382903 0.00507597 0.971095  ]] Max: 2\n",
      "File: FAKE/1 (10).jpg Image shape: (224, 224, 3)\n",
      "Prediction: [[2.5855820e-04 3.6533832e-04 9.9937612e-01]] Max: 2\n"
     ]
    }
   ],
   "source": [
    "# extract prefix path from TEST_FILES_METADATA_CSV\n",
    "prefx_path = Path(TEST_FILES_METADATA_CSV).parent\n",
    "for file in test_files:\n",
    "    file = file[0]\n",
    "    image = preprocess_image(\n",
    "        os.path.join(prefx_path, file),\n",
    "        CropType.RESIZE,\n",
    "    )\n",
    "\n",
    "    print(f\"File: {file} Image shape: {image.shape}\")\n",
    "    predictions = model(np.array([image]))\n",
    "    # take the argmax of the predictions\n",
    "    max_index = np.argmax(predictions)\n",
    "\n",
    "    print(f\"Prediction: {predictions} Max: {max_index}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
