{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from huggingface_hub import from_pretrained_keras, push_to_hub_keras\n",
    "from keras.models import load_model\n",
    "\n",
    "from training_pipeline.data_generator import CropType, preprocess_image\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "MODEL_PATH = os.path.join(os.getcwd(), \"../cache/keras_model/saved_model_rgb_classifier\")\n",
    "TEST_FILES_METADATA_CSV = \"/Volumes/FD/ai_or_not/data/cifake/test/FAKE_metadata.csv\"\n",
    "\n",
    "REPO_ID = \"ai-or-not/ai-or-not-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(TEST_FILES_METADATA_CSV, skiprows=1)\n",
    "test_files = metadata.values\n",
    "test_files = test_files[:10]\n",
    "\n",
    "# extract prefix path from TEST_FILES_METADATA_CSV\n",
    "prefx_path = Path(TEST_FILES_METADATA_CSV).parent\n",
    "for file in test_files:\n",
    "    file = file[0]\n",
    "    image = preprocess_image(\n",
    "        os.path.join(prefx_path, file),\n",
    "        CropType.RESIZE,\n",
    "    )\n",
    "\n",
    "    print(f\"File: {file} Image shape: {image.shape}\")\n",
    "    predictions = model.predict(np.array([image]))\n",
    "    # take the argmax of the predictions\n",
    "    max_index = np.argmax(predictions)\n",
    "\n",
    "    print(f\"Prediction: {predictions} Max: {max_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to huggingface\n",
    "push_to_hub_keras(\n",
    "    model,\n",
    "    repo_id=REPO_ID,\n",
    "    tags=[\"0.1\", \"classification\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = from_pretrained_keras(REPO_ID, token=True, force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefx_path = Path(TEST_FILES_METADATA_CSV).parent\n",
    "for file in test_files:\n",
    "    file = file[0]\n",
    "    image = preprocess_image(\n",
    "        os.path.join(prefx_path, file),\n",
    "        CropType.RESIZE,\n",
    "    )\n",
    "\n",
    "    print(f\"File: {file} Image shape: {image.shape}\")\n",
    "    predictions = model(np.array([image]))\n",
    "    # take the argmax of the predictions\n",
    "    max_index = np.argmax(predictions)\n",
    "\n",
    "    print(f\"Prediction: {predictions} Max: {max_index}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
